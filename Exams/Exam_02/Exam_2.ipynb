{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8649de8-3aba-4b54-8380-64d9b0ec571c",
   "metadata": {},
   "source": [
    "**1. (20 points) True or False.**\n",
    " - **(a) GridSearchCV and Optuna will always produce the same results.** False\n",
    " - **(b) Support vector machine is an ensemble learning technique.** False\n",
    " - **(c) If the classifier produce a 80% recall on test dataset (using default values for hyperparameters), there is no need to tune the classifier hyper-parameters.** False\n",
    " - **(d) RandomSearchCV and Optuna will always produce the same results.** False\n",
    " - **(e) Increasing the value of max depth in tree-based models prevents overfitting.** False\n",
    " - **(f) Scaling the input variables in tree-based models can speed up the hyper-parameter tuning process.** False\n",
    " - **(g) In GridSearchCV, the number of trials can be specified by the practitioner.** False\n",
    " - **(h) XGBoost always outperforms random forest.** False\n",
    " - **(i) XGBoost is faster than regular gradient boosting algorithms because it trains the the base-learners in parallel.** True\n",
    " - **(j) In order to avoid overfitting, it is recommended to tune the learning rate hyperparameter in *random forest* models.** False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10043c88-a010-4248-8aed-eeb0a2fc1aed",
   "metadata": {},
   "source": [
    "**2. (6 points) In what scenarios, RandomSearchCV would be preferred instead of GridSearchCV? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936dfb2-db41-4220-9319-2a5cf55ad516",
   "metadata": {},
   "source": [
    "RandomSearchCV may be preferred over GridSearchCV when the hyperparameter search space is large because GridSearchCV looks at all combinations. It would also be prefered when computational resources are limited. It would also be prefered if you aren't trying to find the best or most optimal combination but one that performs well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137cfca-5c6f-47f9-9ae7-248fcad3601d",
   "metadata": {},
   "source": [
    "**3. (6 points) How does stacking work? Be specific**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8fce0-323f-4771-9d02-4165fb64e148",
   "metadata": {},
   "source": [
    "Stacking is an ensemble learning technique that combines the predictions of multiple base models to make a final prediction. The idea behind stacking is to combine the strengths of the different base models by allowing the meta-learner to learn how to weight the predictions of the base models to improve prediction power. By doing so, the meta-learner can potentially make better predictions than the base models can on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cf1ce-17b6-4d1b-8dc4-d3da5ebad10f",
   "metadata": {},
   "source": [
    "**4. (6 points) If you have trained three different models on the exact same training dataset, and they all achieve a 93% F1-score on the exact same dataset. Is there any chance that you can combine these three models to get better results? If so, how? If not, why? Be specific.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb186cf0-efe1-478d-8a96-b0dbde649b6b",
   "metadata": {},
   "source": [
    "Yes, you could still combine the three models and get improved results. By using the likelihoods from each of the models, you can create an ensemble model that takes the likelihoods as input variables to predict the class. Even if the three models have achieved an F1-Score of 93%, it is still possible for an ensemble model to improve prediction power because it can find new patterns in the likelihoods and potentially get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1d189-5b54-46ba-9d73-1ffc2457cd73",
   "metadata": {},
   "source": [
    "**5. (4 points) If your XGBoost model overfits the data (probably because the number of boosted trees is large), what hyper-parameter you need to tune? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc972d27-db44-4d0e-98ec-ea31f0df1d49",
   "metadata": {},
   "source": [
    "You could tune a number of variables to reduce overfitting. For example, you'd likely want to lower the learning rate which would reduce the influence of each individual tree and could lead to a model that generalizes better to new data. So, the model is less sensitive to the large number of trees that was likely the cause.\n",
    "\n",
    "Alternatively, a large number of trees can also cause overfitting on its own. When there are too many trees, the model becomes too complex and starts fitting the noise in the data, instead of underlying patterns. By decreasing the number of trees, the model becomes simpler and more generalizable, which can help reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc90852-5373-4c34-964c-8ab784544829",
   "metadata": {},
   "source": [
    "**6. (4 points) Which of the following algorithm is NOT an ensemble learning algorithm?**\n",
    " - **(a) support vector machine**\n",
    " - **(b) random forest**\n",
    " - **(c) AdaBoost**\n",
    " - **(d) XGBoost**\n",
    " - **(e) None of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cbb0a-46c5-447a-889f-134e356cf458",
   "metadata": {
    "tags": []
   },
   "source": [
    "(a) SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eced555-ee1a-4617-909a-80906449283e",
   "metadata": {},
   "source": [
    "**7. (6 points) How does XGBoost with random forest as base learner work? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156ec0e-0315-452d-beff-3444f1c129a0",
   "metadata": {},
   "source": [
    "XGBoost does not allow for Random Forest to be selected as an option for the 'booster' hyper-parameter. However, Random Forest can still be incorporated into an XGBoost model by adjusting the 'num_parallel_trees' hyper-parameter to a value greater than 1. Essentially, this modification allows the model to use multiple trees in parallel for each boosting round, similar to a Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1333c-b724-4cd7-9d35-ed432a28e584",
   "metadata": {},
   "source": [
    "**8. (4 points) How do we select the best hyper-parameter combination for a given model?**\n",
    " - **(a) Performance on the training dataset**\n",
    " - **(b) Performance on the validation dataset**\n",
    " - **(c) (a) and (b)**\n",
    " - **(d) None of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261fb4d-18cd-4dac-8896-c0199c1c85e1",
   "metadata": {},
   "source": [
    "(b) Performance on the validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93c98a-49e1-42ef-8884-693b0dfb4498",
   "metadata": {},
   "source": [
    "**9. The below chart shows the performance of a random forest models (with different number of trees).**\n",
    "\n",
    "**Using the above chart, answer parts (a)-(b).**\n",
    "\n",
    "**(a) (4 points) If a data scientist wants to tune the number of trees based on the F1-score, how many trees would he select? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f5926-c369-4e01-a823-2043f13cfe39",
   "metadata": {},
   "source": [
    "If the data scientist is tuning the number of trees based on the F1-score, they should select 400 trees because there is little to no prediction improvement in the train and test sets after increasing the number of trees past 400. Increasing beyond this point would result in increased computation time with little to no model improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445a99b-ab47-4e70-ae9f-484496642bef",
   "metadata": {},
   "source": [
    "**(b) (6 points) What is the reason there is big difference in the F1-score performance between the Train and Test datasets? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec85682-866f-46c1-b973-8181ede18998",
   "metadata": {},
   "source": [
    "The biggest reason why there would be a huge difference in the F1-score performance between the train and test datasets is that the model is likely overfitting the on the training data. The model fits the training data very well, but does not do a great job of generalizing on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb363085-eb58-4212-b4c5-af2247d392a1",
   "metadata": {},
   "source": [
    "**10. (6 points) What is the difference between homogeneous and heterogeneous ensembles? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7cbea-dd46-466a-a60e-cbf8de150981",
   "metadata": {},
   "source": [
    "A heterogeneous ensemble method refers to an ensemble model that uses different algorithms for the base learners, whereas a homogeneous ensemble refers to an ensemble model that uses the same algorithm for all the base learners on different distributions of the training dataset. Homogeneous ensembles are typically used to improve the performance of a single type of model, while heterogeneous ensembles are used to combine the strengths of multiple models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81275a8-8208-4759-bdd3-8f9bc9fbcef2",
   "metadata": {},
   "source": [
    "**11. (4 points) Random forest is an example of**\n",
    " - **(a) Homogeneous ensemble**\n",
    " - **(b) Heterogeneous ensemble**\n",
    " - **(c) Bagging**\n",
    " - **(c) (a) and (b)**\n",
    " - **(d) (a) and (c)**\n",
    " - **(e) (b) and (c)**\n",
    " - **(f) None of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3edf60-250f-4c83-8397-a4cf7faec3d2",
   "metadata": {},
   "source": [
    "(d) (a) and (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d312c98-0009-46df-9b37-6982de2c95c6",
   "metadata": {},
   "source": [
    "**12. (8 points) A junior data scientist is working on building a classification framework that can help a small local credit union to identify fraudulent transactions. The data scientist collects a very small dataset with 100 observations, from which 4 observations are labelled as fraudulent, to start building and tuning the model. As part of the tuning process, the data scientist considers using the GridSearch function from scikit-learn with cv = 5. Explain why this approach is a good idea or not. Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa8054-793d-4370-8892-d89fc1f2956d",
   "metadata": {},
   "source": [
    "This approach is not a good idea because GridSearchCV uses a stratified k-fold approach, which means that by setting cv = 5, it splits the 100 observation set into five data sets that are meant to contained a stratified sample of the class of interest (fraud). However, since there are only 4 fraud observations for 5 folds, one fold is not going to have a fraudulent observation. Ultimately, the approach is not a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602653b2-f932-4b74-9bd0-a8afdb4b34f3",
   "metadata": {},
   "source": [
    "**13. The typical hyper-parameters in a XGBoost model that data science practitioners tune are:**\n",
    " - **n estimators**\n",
    " - **learning rate**\n",
    " - **max depth**\n",
    " - **min child weight**\n",
    " - **subsample**\n",
    " - **colsample bytree**\n",
    " \n",
    "**(a) (4 points) What is/are the hyper-parameters that may cause overfitting if we increase their values while holding the values of the hyper-parameters constant? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d72fab-c7f8-44a9-8fe2-2cd5577f0648",
   "metadata": {},
   "source": [
    "Increasing the values for learning rate, max depth, subsample, and colsample bytree while holding all other values constant may cause overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a51e7b-e2f2-4f5d-953a-f0924cd93db9",
   "metadata": {},
   "source": [
    "**(b) (4 points) What is/are the hyper-parameters that prevents overfitting if we increase their values while holding the values of the hyper-parameters constant? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73347b73-33f5-47d3-a471-88ae2d61379e",
   "metadata": {},
   "source": [
    "Increasing the value for min child weight while holding all other values constant may prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad657c-6aa8-4e73-bd79-6fa77accab3b",
   "metadata": {},
   "source": [
    "**14. (6 points) In tree-based models such as random forest, gradient boosting, and XGBoost, how does a data scientist optimize the number of trees in a manually fashion? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44acf40-d5e7-4fc2-a7b3-8e0646dd2c6b",
   "metadata": {},
   "source": [
    "The number of trees can be tuned with the n_estimators hyper-parameter. This value can be optimized/tuned with a tuning method like RandomizedSearchCV, GridSearchCV, or Optuna. Alternatively, the data scientist could optimize this number by testing various numbers for n_trees and plotting the performance of the model on the train and test sets. This would allow the data scientist to examinine the plotted curve and determine the optimal number of trees that maximizes the performance of the model on the test set while minimizing overfitting to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2115dc0-17da-40fd-9e0b-d90a1f9e035a",
   "metadata": {},
   "source": [
    "**15. A Machine Learning Specialist is assigned to a team that is responsible for tuning an XGBoost model to ensure that it performs correctly on test data. However, when dealing with unknown data, this does not operate as planned. The following table summarizes the existing hyper-parameters:**\n",
    "\n",
    "    XGBoost_params = {'n_estimators': 2000,\n",
    "                      'max_depth': 30,\n",
    "                      'min_child_weight': 3,\n",
    "                      'subsample': 0.9,\n",
    "                      'objective': 'reg:squarederror'}\n",
    "                      \n",
    "**(a) (3 points) What type of task the machine learning specialist is working on? Classification or regression? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e1119-1078-41f2-963d-0f70e44ef95d",
   "metadata": {},
   "source": [
    "The machine learning specialist is working on a regression task because the objective is set to \"reg:squarederror\". This is the default setting for onjective in XGBoost regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13328e-6558-4e38-a992-b22190a95b3f",
   "metadata": {},
   "source": [
    "**(b) (5 points) Given the existing XGBoost hyper-parameters, what may be the reason that the XGBoost model is not performing as expected? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f4e2a-5176-4293-9e24-59d50eb62f4a",
   "metadata": {},
   "source": [
    "Looking at the hyper-parameters for the XGBoost model, it may not be performing as expected because the n_estimators and max_depth values are likely causing the model to be overfit. A max depth of 30 is very large and is likely the main culprit in causing the modle to overfit. Though increasing the number of trees can improve the result, 2000 may be also be too many to consider for their model. Similarly, decreasing the max depth will  likely decrease the likelihood that the model is overfit. Overall, they should consider changes to n_estimators and max_depth to reduce overfitting on the training data and hopefully see some increased model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff68ff-2e46-406c-a848-eb44bac59e26",
   "metadata": {},
   "source": [
    "**16. (8 points) How can overfitting and underfitting be addressed through hyper-parameter tuning in random forest? That is, what hyper-parameters would you tune to address overfitting and underfitting in random forest? Be specific.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cc2db-d66a-4959-a2c8-b513132f9322",
   "metadata": {},
   "source": [
    "You can address over/under fitting in a random forest model by tuning various hyper-parameters. For example:\n",
    " - n_estimators: the number of trees in the forest. \n",
    "   - decreasing the number of trees can reduce overfitting\n",
    "   - increasing the number of trees can reduce underfitting\n",
    " - max_depth: sets the maximum depth of each tree in the forest.\n",
    "   - decreasing the depth can reduce overfitting\n",
    "   - increasing the depth can reduce underfitting\n",
    " - min_samples_split: sets the minimum number of samples required to split an internal node. \n",
    "   - increasing this parameter can reduce overfitting\n",
    "   - decreasing this parameter can reduce underfitting\n",
    " - min_samples_leaf: sets the minimum number of samples required to be at a leaf node.\n",
    "    - increasing this parameter can reduce overfitting\n",
    "    - decreasing this parameter can reduce underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74366f6-4c43-461e-8650-cec56adfe033",
   "metadata": {},
   "source": [
    "**17. Consider the Customers.csv data file. This file contains basic information on customer data. The owner of a shop gets information about Customers through membership cards. This dataset consists of 2000 records and 8 columns:**\n",
    " - Customer ID: customer ID.\n",
    " - Gender: customer's gender.\n",
    " - AGE: customer's age in years.\n",
    " - Annual Income: customer's annual income.\n",
    " - Spending Score: Score assigned by the shop, based on customer behavior and spending nature.\n",
    " - Profession: customer's profession.\n",
    " - Work Experience: customer's work experience in years.\n",
    " - Family Size: number of family members.\n",
    " \n",
    "**The goal is to predict Spending Score; that is, this a regression task. This is a continuation from Exercise 16 in Exam 1. In Python, answer the following:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2a73e8-d375-4ef5-8dc1-208ae8455ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optuna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.4.46)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: colorlog in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.10.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: Mako in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed1627f-0487-4fbc-b0cd-0c3ff8cac352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643f945-1ff8-46d9-b6f0-bdbcb5d8c0f4",
   "metadata": {},
   "source": [
    "*(a) (4 points) Using the pandas library, read the Customers.csv data file and create a dataframe called customers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71868642-9651-4ca2-b7cc-c1d53b812d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income ($)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work Experience</th>\n",
       "      <th>Family Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15000</td>\n",
       "      <td>39</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>35000</td>\n",
       "      <td>81</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>86000</td>\n",
       "      <td>6</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>59000</td>\n",
       "      <td>77</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>38000</td>\n",
       "      <td>40</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender  Age  Annual Income ($)  Spending Score (1-100)  \\\n",
       "0           1    Male   19              15000                      39   \n",
       "1           2    Male   21              35000                      81   \n",
       "2           3  Female   20              86000                       6   \n",
       "3           4  Female   23              59000                      77   \n",
       "4           5  Female   31              38000                      40   \n",
       "\n",
       "      Profession  Work Experience  Family Size  \n",
       "0     Healthcare                1            4  \n",
       "1       Engineer                3            3  \n",
       "2       Engineer                1            1  \n",
       "3         Lawyer                0            2  \n",
       "4  Entertainment                2            6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'craig-shaffer-data-445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "#defining the file to be read from s3 bucket\n",
    "file_key = 'Customers_Exam2.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "#reading the datafile\n",
    "customers = pd.read_csv(file_content_stream)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50346cc-e7b8-4a8a-838a-e54bf29581fd",
   "metadata": {},
   "source": [
    "*(b) (3 points) Drop the Customer ID variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1be10a-ff07-40c1-b51b-c6990d83d01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income ($)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work Experience</th>\n",
       "      <th>Family Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15000</td>\n",
       "      <td>39</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>35000</td>\n",
       "      <td>81</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>86000</td>\n",
       "      <td>6</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>59000</td>\n",
       "      <td>77</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>38000</td>\n",
       "      <td>40</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Annual Income ($)  Spending Score (1-100)     Profession  \\\n",
       "0    Male   19              15000                      39     Healthcare   \n",
       "1    Male   21              35000                      81       Engineer   \n",
       "2  Female   20              86000                       6       Engineer   \n",
       "3  Female   23              59000                      77         Lawyer   \n",
       "4  Female   31              38000                      40  Entertainment   \n",
       "\n",
       "   Work Experience  Family Size  \n",
       "0                1            4  \n",
       "1                3            3  \n",
       "2                1            1  \n",
       "3                0            2  \n",
       "4                2            6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping CustomerID\n",
    "customers = customers.drop(columns = 'CustomerID')\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2deb7721-0cc0-4673-ad31-14e9ccbd9f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Profession']\n",
      "{'Gender': 'Female', 'Profession': 'Artist'}\n"
     ]
    }
   ],
   "source": [
    "#imputing missing variables with most frequent label like in Exam 1\n",
    " \n",
    "#identifying categorical variables\n",
    "categorical_vars = customers.select_dtypes(include = 'object').columns.to_list()\n",
    "print(categorical_vars)\n",
    "\n",
    "#frequent values for each categorical variable (profession is the one we care about)\n",
    "frequent_values = customers[categorical_vars].mode().iloc[0].to_dict()\n",
    "print(frequent_values)\n",
    "\n",
    "#creating indicator variable for observations with imputed profession (1 for imputed, 0 if not)\n",
    "customers['Profession_imputed'] = customers['Profession'].isna().astype(int)\n",
    "\n",
    "#filling missing values with most frequent labels\n",
    "customers = customers.fillna(value = frequent_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72044379-32da-44e6-8e3d-f3f40a32d3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changing Profession to dummies\n",
    "customers = pd.concat([customers.drop(columns=['Profession'],axis=1), pd.get_dummies(customers[['Profession']])],axis=1)\n",
    "\n",
    "#changing gender to labels (female-0, male-1)\n",
    "customers['Gender'].replace(['Male', 'Female'], [1,0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a24b5f-88c8-4ae8-860c-7b9b9f1c087f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding engineered features from Exam 1\n",
    "\n",
    "#Features 1 & 2: heredity principle features based on feature importances \n",
    "customers['heredity_feature_1'] = customers['Annual Income ($)'] * customers['Age']\n",
    "customers['heredity_feature_2'] = customers['Annual Income ($)'] * customers['Work Experience']\n",
    "\n",
    "#Feature 3: Annual Income divided by Family Size\n",
    "customers['IncomeOverFamily'] = customers['Annual Income ($)'] / customers['Family Size']\n",
    "\n",
    "#Feature 4: Work Experience ^ 2\n",
    "customers['squared_WorkExperience']= np.power(customers['Work Experience'], 2)\n",
    "\n",
    "#Feature 5: Annual Income ^ 2\n",
    "customers['squared_AnnualIncome']= np.power(customers['Annual Income ($)'], 2)\n",
    "\n",
    "#Feature 6: natural log of Family Size\n",
    "customers['log_FamilySize']= np.log(customers['Family Size'])\n",
    "\n",
    "#Feature 7 & 8: tree interactions based on patterns in Decision Tree models\n",
    "customers['tree_interaction_1'] = np.where((customers['heredity_feature_1'] <=14537703.5) & \n",
    "                                         (customers['Age'] > 32.5) &\n",
    "                                         (customers['heredity_feature_1'] > 3194215.0), 1, 0)\n",
    "customers['tree_interaction_2'] = np.where((customers['heredity_feature_1'] <=14537703.5) & \n",
    "                                         (customers['Age'] <= 32.5) &\n",
    "                                         (customers['IncomeOverFamily'] > 37307.033), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd9c68-3c68-4fbe-8189-0093a05ba0c4",
   "metadata": {},
   "source": [
    "*(c) (5 points) Split the customers data-frame into: train (80%) and test (20%).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53039db2-65e6-4191-92a9-7b3a114ac28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining input and target\n",
    "x=customers[['heredity_feature_1','IncomeOverFamily','heredity_feature_2','Annual Income ($)','Age','Work Experience','log_FamilySize']]\n",
    "y=customers['Spending Score (1-100)']\n",
    "\n",
    "#splitting the data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ccdbdc-ad71-47b9-84e2-c1d6595ca7e2",
   "metadata": {},
   "source": [
    "*(d) (20 points) Using results from Exercise 16 part (e) in Exam 1, use the top 7 variables, build a model on the train data-frame, and tune this model using the Optuna framework. Notice that you need to tune the model based on the root mean squared error. Then, use the optimal model to make predictions on the test data-frame. Finally, compute the root mean squared error of the model. Make sure to run at least 50 trials the Optuna framework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19656c9b-d10e-4909-b681-ef9d9e586002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-04 21:17:03,788]\u001b[0m A new study created in memory with name: no-name-4dfa2078-3ce6-4b3c-a483-2c86a89e68dc\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:17:13,638]\u001b[0m Trial 0 finished with value: 28.316518846655928 and parameters: {'n_estimators': 1213, 'min_samples_split': 28, 'min_samples_leaf': 29, 'max_depth': 7}. Best is trial 0 with value: 28.316518846655928.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:17:17,931]\u001b[0m Trial 1 finished with value: 28.32958270330349 and parameters: {'n_estimators': 513, 'min_samples_split': 18, 'min_samples_leaf': 17, 'max_depth': 6}. Best is trial 0 with value: 28.316518846655928.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:17:19,744]\u001b[0m Trial 2 finished with value: 28.22993100623749 and parameters: {'n_estimators': 225, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_depth': 5}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:17:33,174]\u001b[0m Trial 3 finished with value: 28.441668363904785 and parameters: {'n_estimators': 1558, 'min_samples_split': 7, 'min_samples_leaf': 22, 'max_depth': 9}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:17:46,562]\u001b[0m Trial 4 finished with value: 28.4195884801603 and parameters: {'n_estimators': 1531, 'min_samples_split': 16, 'min_samples_leaf': 15, 'max_depth': 7}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:00,661]\u001b[0m Trial 5 finished with value: 28.318947606018224 and parameters: {'n_estimators': 1809, 'min_samples_split': 12, 'min_samples_leaf': 29, 'max_depth': 7}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:03,727]\u001b[0m Trial 6 finished with value: 28.24379771919659 and parameters: {'n_estimators': 411, 'min_samples_split': 21, 'min_samples_leaf': 25, 'max_depth': 5}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:20,142]\u001b[0m Trial 7 finished with value: 28.479908735209236 and parameters: {'n_estimators': 1837, 'min_samples_split': 15, 'min_samples_leaf': 18, 'max_depth': 9}. Best is trial 2 with value: 28.22993100623749.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:24,090]\u001b[0m Trial 8 finished with value: 28.02601636331384 and parameters: {'n_estimators': 743, 'min_samples_split': 6, 'min_samples_leaf': 27, 'max_depth': 2}. Best is trial 8 with value: 28.02601636331384.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:33,655]\u001b[0m Trial 9 finished with value: 28.063017656154063 and parameters: {'n_estimators': 1536, 'min_samples_split': 22, 'min_samples_leaf': 6, 'max_depth': 3}. Best is trial 8 with value: 28.02601636331384.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:38,122]\u001b[0m Trial 10 finished with value: 28.011505282796676 and parameters: {'n_estimators': 833, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 10 with value: 28.011505282796676.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:18:42,432]\u001b[0m Trial 11 finished with value: 28.010761754876274 and parameters: {'n_estimators': 803, 'min_samples_split': 5, 'min_samples_leaf': 11, 'max_depth': 2}. Best is trial 11 with value: 28.010761754876274.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:47,371]\u001b[0m Trial 12 finished with value: 28.010546172513685 and parameters: {'n_estimators': 920, 'min_samples_split': 11, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:18:55,282]\u001b[0m Trial 13 finished with value: 28.156358418516998 and parameters: {'n_estimators': 1118, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_depth': 4}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:19:00,488]\u001b[0m Trial 14 finished with value: 28.07297903143868 and parameters: {'n_estimators': 829, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_depth': 3}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:06,045]\u001b[0m Trial 15 finished with value: 28.019815770966158 and parameters: {'n_estimators': 1004, 'min_samples_split': 9, 'min_samples_leaf': 14, 'max_depth': 2}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:10,149]\u001b[0m Trial 16 finished with value: 28.135718120576772 and parameters: {'n_estimators': 574, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_depth': 4}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:10,876]\u001b[0m Trial 17 finished with value: 28.118114205349432 and parameters: {'n_estimators': 113, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_depth': 3}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:24,395]\u001b[0m Trial 18 finished with value: 28.664988822829244 and parameters: {'n_estimators': 1286, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_depth': 10}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:31,360]\u001b[0m Trial 19 finished with value: 28.16664102550891 and parameters: {'n_estimators': 989, 'min_samples_split': 30, 'min_samples_leaf': 13, 'max_depth': 4}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:19:34,936]\u001b[0m Trial 20 finished with value: 28.016594113266535 and parameters: {'n_estimators': 664, 'min_samples_split': 19, 'min_samples_leaf': 16, 'max_depth': 2}. Best is trial 12 with value: 28.010546172513685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:39,505]\u001b[0m Trial 21 finished with value: 28.009766445365727 and parameters: {'n_estimators': 849, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:19:45,384]\u001b[0m Trial 22 finished with value: 28.06241804962679 and parameters: {'n_estimators': 932, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_depth': 3}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:19:52,513]\u001b[0m Trial 23 finished with value: 28.01719995240404 and parameters: {'n_estimators': 1326, 'min_samples_split': 5, 'min_samples_leaf': 13, 'max_depth': 2}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:19:54,779]\u001b[0m Trial 24 finished with value: 28.054760564905234 and parameters: {'n_estimators': 355, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_depth': 3}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:19:59,888]\u001b[0m Trial 25 finished with value: 28.230267665713896 and parameters: {'n_estimators': 649, 'min_samples_split': 10, 'min_samples_leaf': 11, 'max_depth': 5}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:20:05,490]\u001b[0m Trial 26 finished with value: 28.177739762259463 and parameters: {'n_estimators': 808, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_depth': 4}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:20:11,451]\u001b[0m Trial 27 finished with value: 28.020242143416066 and parameters: {'n_estimators': 1122, 'min_samples_split': 8, 'min_samples_leaf': 15, 'max_depth': 2}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:20:17,166]\u001b[0m Trial 28 finished with value: 28.100524137261228 and parameters: {'n_estimators': 918, 'min_samples_split': 12, 'min_samples_leaf': 21, 'max_depth': 3}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:20:27,389]\u001b[0m Trial 29 finished with value: 28.29982913360931 and parameters: {'n_estimators': 1202, 'min_samples_split': 25, 'min_samples_leaf': 8, 'max_depth': 6}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:20:31,269]\u001b[0m Trial 30 finished with value: 28.497902687252843 and parameters: {'n_estimators': 406, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_depth': 8}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:20:35,818]\u001b[0m Trial 31 finished with value: 28.010037921096842 and parameters: {'n_estimators': 857, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 21 with value: 28.009766445365727.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:20:39,531]\u001b[0m Trial 32 finished with value: 28.006128170162423 and parameters: {'n_estimators': 696, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:20:43,015]\u001b[0m Trial 33 finished with value: 28.09581100750994 and parameters: {'n_estimators': 563, 'min_samples_split': 7, 'min_samples_leaf': 17, 'max_depth': 3}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:20:46,660]\u001b[0m Trial 34 finished with value: 28.012496092467362 and parameters: {'n_estimators': 685, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:20:53,060]\u001b[0m Trial 35 finished with value: 28.16188210385042 and parameters: {'n_estimators': 917, 'min_samples_split': 17, 'min_samples_leaf': 15, 'max_depth': 4}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:02,039]\u001b[0m Trial 36 finished with value: 28.230109084829095 and parameters: {'n_estimators': 1140, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_depth': 5}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:05,186]\u001b[0m Trial 37 finished with value: 28.07845319131876 and parameters: {'n_estimators': 501, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_depth': 3}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:12,144]\u001b[0m Trial 38 finished with value: 28.020185037094546 and parameters: {'n_estimators': 1314, 'min_samples_split': 6, 'min_samples_leaf': 16, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:19,898]\u001b[0m Trial 39 finished with value: 28.01275383069005 and parameters: {'n_estimators': 1434, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:26,257]\u001b[0m Trial 40 finished with value: 28.084688068011843 and parameters: {'n_estimators': 1028, 'min_samples_split': 15, 'min_samples_leaf': 14, 'max_depth': 3}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:30,335]\u001b[0m Trial 41 finished with value: 28.016461125648714 and parameters: {'n_estimators': 766, 'min_samples_split': 5, 'min_samples_leaf': 11, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:34,902]\u001b[0m Trial 42 finished with value: 28.011300034309343 and parameters: {'n_estimators': 859, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:38,771]\u001b[0m Trial 43 finished with value: 28.027842296227604 and parameters: {'n_estimators': 729, 'min_samples_split': 8, 'min_samples_leaf': 23, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:45,364]\u001b[0m Trial 44 finished with value: 28.080119934498857 and parameters: {'n_estimators': 1068, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_depth': 3}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:48,797]\u001b[0m Trial 45 finished with value: 28.13745509668199 and parameters: {'n_estimators': 483, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_depth': 4}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:21:54,390]\u001b[0m Trial 46 finished with value: 28.440657837158682 and parameters: {'n_estimators': 620, 'min_samples_split': 6, 'min_samples_leaf': 12, 'max_depth': 7}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:21:56,105]\u001b[0m Trial 47 finished with value: 28.031722657392706 and parameters: {'n_estimators': 316, 'min_samples_split': 12, 'min_samples_leaf': 18, 'max_depth': 2}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:22:13,028]\u001b[0m Trial 48 finished with value: 28.495985182317554 and parameters: {'n_estimators': 1744, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_depth': 8}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:22:19,772]\u001b[0m Trial 49 finished with value: 28.248478331073745 and parameters: {'n_estimators': 876, 'min_samples_split': 21, 'min_samples_leaf': 16, 'max_depth': 5}. Best is trial 32 with value: 28.006128170162423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination for RandomForestRegressor with top-7 variables: \n",
      " {'n_estimators': 696, 'min_samples_split': 5, 'min_samples_leaf': 12, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "#Model: Random Forest\n",
    "\n",
    "SEED = 42\n",
    "N_TRIALS = 50\n",
    "\n",
    "#Optuna w/ top 7 most important features:----------\n",
    "class Objective:\n",
    "    \n",
    "    def __init__(self, seed):\n",
    "        \n",
    "        self.seed = seed\n",
    "        \n",
    "    def __call__(self, trial):\n",
    "        \n",
    "        params = dict(n_estimators = trial.suggest_int('n_estimators', 100, 2000), \n",
    "                      min_samples_split = trial.suggest_int('min_samples_split', 5, 30),\n",
    "                      min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 30),\n",
    "                      max_depth = trial.suggest_int('max_depth', 2, 10))\n",
    "        \n",
    "        scores = list()\n",
    "        \n",
    "        skf = KFold(n_splits = 3, shuffle = True, random_state = self.seed)\n",
    "        \n",
    "        for train_idx, valid_idx in skf.split(x_train, y_train):\n",
    "            \n",
    "            x_train_1, x_valid_1 = x_train.iloc[train_idx], x_train.iloc[valid_idx]\n",
    "            y_train_1, y_valid_1 = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "            \n",
    "            rf_md = RandomForestRegressor(**params).fit(x_train_1,y_train_1)\n",
    "            \n",
    "            pred_valid = rf_md.predict(x_valid_1)\n",
    "            \n",
    "            scores.append(mean_squared_error(y_valid_1, pred_valid, squared = False))   \n",
    "            \n",
    "        return np.mean(scores)\n",
    "\n",
    "study_1 = optuna.create_study(direction = 'minimize')\n",
    "study_1.optimize(Objective(SEED), n_trials = N_TRIALS)\n",
    "\n",
    "print('Best hyper-parameter combination for RandomForestRegressor with top-7 variables: \\n', study_1.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "038267f6-aac7-47da-8290-e063be82e39c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE of the Random Forest model is:  27.734948112775353\n"
     ]
    }
   ],
   "source": [
    "#running model with best parameters\n",
    "rf_md = RandomForestRegressor(**study_1.best_trial.params).fit(x_train, y_train)\n",
    "\n",
    "#predicting on test\n",
    "rf_pred = rf_md.predict(x_test)\n",
    "\n",
    "#computing rmse\n",
    "rf_results = mean_squared_error(y_test, rf_pred, squared = False)\n",
    "print('the RMSE of the Random Forest model is: ', rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f83a4-5bf0-47e3-a82c-752c21d8ae76",
   "metadata": {},
   "source": [
    "*(e) (20 points) Using results from Exercise 16 part (e) in Exam 1, use the top 7 variables, build another model (different from the one in part (d)) on the train data-frame, and tune this model using the Optuna framework. Notice that you need to tune the model based on the root mean squared error. Then, use the optimal model to make predictions on the test data-frame. Finally, compute the root mean squared error of the model. Make sure to run at least 50 trials the Optuna framework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97e1ac9-6f04-4dad-9100-d9a4e65500ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-04 21:44:28,645]\u001b[0m A new study created in memory with name: no-name-c567061b-8069-4621-9beb-2518a6def915\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:44:40,583]\u001b[0m Trial 0 finished with value: 33.2560865757852 and parameters: {'n_estimators': 990, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_depth': 7, 'learning_rate': 0.08214941584163381}. Best is trial 0 with value: 33.2560865757852.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:44:49,486]\u001b[0m Trial 1 finished with value: 30.67711880698395 and parameters: {'n_estimators': 627, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_depth': 9, 'learning_rate': 0.016369061213959972}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:44:54,876]\u001b[0m Trial 2 finished with value: 30.914532691824004 and parameters: {'n_estimators': 614, 'min_samples_split': 26, 'min_samples_leaf': 25, 'max_depth': 5, 'learning_rate': 0.049592992308554046}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:45:18,599]\u001b[0m Trial 3 finished with value: 34.437088047461664 and parameters: {'n_estimators': 1631, 'min_samples_split': 9, 'min_samples_leaf': 19, 'max_depth': 10, 'learning_rate': 0.05936750839992856}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:45:36,428]\u001b[0m Trial 4 finished with value: 34.66521521207665 and parameters: {'n_estimators': 1468, 'min_samples_split': 9, 'min_samples_leaf': 23, 'max_depth': 8, 'learning_rate': 0.07679589865919038}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:45:43,141]\u001b[0m Trial 5 finished with value: 31.705460350583376 and parameters: {'n_estimators': 1074, 'min_samples_split': 15, 'min_samples_leaf': 19, 'max_depth': 3, 'learning_rate': 0.07134770279366498}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:45:55,756]\u001b[0m Trial 6 finished with value: 34.039599861777305 and parameters: {'n_estimators': 1622, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_depth': 4, 'learning_rate': 0.07512665106785923}. Best is trial 1 with value: 30.67711880698395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:45:59,896]\u001b[0m Trial 7 finished with value: 29.811831747392148 and parameters: {'n_estimators': 668, 'min_samples_split': 20, 'min_samples_leaf': 25, 'max_depth': 3, 'learning_rate': 0.04354563413144404}. Best is trial 7 with value: 29.811831747392148.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:46:07,663]\u001b[0m Trial 8 finished with value: 29.74112830376221 and parameters: {'n_estimators': 615, 'min_samples_split': 30, 'min_samples_leaf': 26, 'max_depth': 9, 'learning_rate': 0.011666025651463286}. Best is trial 8 with value: 29.74112830376221.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 21:46:21,773]\u001b[0m Trial 9 finished with value: 29.47882197216332 and parameters: {'n_estimators': 1075, 'min_samples_split': 29, 'min_samples_leaf': 7, 'max_depth': 8, 'learning_rate': 0.005006983356332882}. Best is trial 9 with value: 29.47882197216332.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:46:23,090]\u001b[0m Trial 10 finished with value: 30.543410835258612 and parameters: {'n_estimators': 124, 'min_samples_split': 22, 'min_samples_leaf': 12, 'max_depth': 6, 'learning_rate': 0.09997411988674637}. Best is trial 9 with value: 29.47882197216332.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:46:37,753]\u001b[0m Trial 11 finished with value: 29.278781171059226 and parameters: {'n_estimators': 1164, 'min_samples_split': 30, 'min_samples_leaf': 30, 'max_depth': 10, 'learning_rate': 0.0035507683842449763}. Best is trial 11 with value: 29.278781171059226.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:46:52,935]\u001b[0m Trial 12 finished with value: 29.33046462533534 and parameters: {'n_estimators': 1209, 'min_samples_split': 30, 'min_samples_leaf': 30, 'max_depth': 10, 'learning_rate': 0.003556948992915915}. Best is trial 11 with value: 29.278781171059226.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:47:18,875]\u001b[0m Trial 13 finished with value: 32.86082808535766 and parameters: {'n_estimators': 1925, 'min_samples_split': 25, 'min_samples_leaf': 30, 'max_depth': 10, 'learning_rate': 0.025588940616285485}. Best is trial 11 with value: 29.278781171059226.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:47:34,257]\u001b[0m Trial 14 finished with value: 28.623270244588507 and parameters: {'n_estimators': 1310, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_depth': 10, 'learning_rate': 0.0011914249283990139}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:47:49,955]\u001b[0m Trial 15 finished with value: 32.395189620397936 and parameters: {'n_estimators': 1363, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_depth': 7, 'learning_rate': 0.02714017019818229}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:01,354]\u001b[0m Trial 16 finished with value: 28.989170591493377 and parameters: {'n_estimators': 891, 'min_samples_split': 5, 'min_samples_leaf': 22, 'max_depth': 9, 'learning_rate': 0.003688058378435967}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:12,545]\u001b[0m Trial 17 finished with value: 31.46771201977027 and parameters: {'n_estimators': 896, 'min_samples_split': 5, 'min_samples_leaf': 21, 'max_depth': 8, 'learning_rate': 0.026814692776306763}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:16,065]\u001b[0m Trial 18 finished with value: 29.44838289859246 and parameters: {'n_estimators': 260, 'min_samples_split': 7, 'min_samples_leaf': 16, 'max_depth': 9, 'learning_rate': 0.017165857837500884}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:34,875]\u001b[0m Trial 19 finished with value: 32.90795461093587 and parameters: {'n_estimators': 1943, 'min_samples_split': 12, 'min_samples_leaf': 27, 'max_depth': 6, 'learning_rate': 0.037874350512429385}. Best is trial 14 with value: 28.623270244588507.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:38,833]\u001b[0m Trial 20 finished with value: 27.996189658130096 and parameters: {'n_estimators': 825, 'min_samples_split': 18, 'min_samples_leaf': 22, 'max_depth': 2, 'learning_rate': 0.0015470635225693806}. Best is trial 20 with value: 27.996189658130096.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:44,877]\u001b[0m Trial 21 finished with value: 28.328324949467973 and parameters: {'n_estimators': 805, 'min_samples_split': 20, 'min_samples_leaf': 22, 'max_depth': 4, 'learning_rate': 0.003156911828772712}. Best is trial 20 with value: 27.996189658130096.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:46,888]\u001b[0m Trial 22 finished with value: 27.945050870082444 and parameters: {'n_estimators': 415, 'min_samples_split': 18, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.0010455987458644314}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:48,718]\u001b[0m Trial 23 finished with value: 28.23175066986086 and parameters: {'n_estimators': 376, 'min_samples_split': 18, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.014497090468018444}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:50,700]\u001b[0m Trial 24 finished with value: 28.206789196877324 and parameters: {'n_estimators': 410, 'min_samples_split': 19, 'min_samples_leaf': 19, 'max_depth': 2, 'learning_rate': 0.012533961646720812}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:52,782]\u001b[0m Trial 25 finished with value: 28.18396692904848 and parameters: {'n_estimators': 430, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_depth': 2, 'learning_rate': 0.010762959398772153}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:55,371]\u001b[0m Trial 26 finished with value: 28.910854199812217 and parameters: {'n_estimators': 412, 'min_samples_split': 23, 'min_samples_leaf': 14, 'max_depth': 3, 'learning_rate': 0.024291583754844793}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:56,022]\u001b[0m Trial 27 finished with value: 27.976719615444512 and parameters: {'n_estimators': 128, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_depth': 2, 'learning_rate': 0.009984068134714471}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:48:57,156]\u001b[0m Trial 28 finished with value: 28.425845939396595 and parameters: {'n_estimators': 142, 'min_samples_split': 17, 'min_samples_leaf': 17, 'max_depth': 4, 'learning_rate': 0.021156161080409283}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:01,930]\u001b[0m Trial 29 finished with value: 29.85944538155519 and parameters: {'n_estimators': 764, 'min_samples_split': 15, 'min_samples_leaf': 12, 'max_depth': 3, 'learning_rate': 0.029432223875374655}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:03,324]\u001b[0m Trial 30 finished with value: 28.084566046027536 and parameters: {'n_estimators': 286, 'min_samples_split': 22, 'min_samples_leaf': 24, 'max_depth': 2, 'learning_rate': 0.009665979189616432}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:04,519]\u001b[0m Trial 31 finished with value: 28.065593690535064 and parameters: {'n_estimators': 244, 'min_samples_split': 22, 'min_samples_leaf': 24, 'max_depth': 2, 'learning_rate': 0.010189424688136446}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:05,731]\u001b[0m Trial 32 finished with value: 28.18986837607299 and parameters: {'n_estimators': 247, 'min_samples_split': 16, 'min_samples_leaf': 28, 'max_depth': 2, 'learning_rate': 0.017612279340419194}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:08,928]\u001b[0m Trial 33 finished with value: 28.383075027081375 and parameters: {'n_estimators': 514, 'min_samples_split': 13, 'min_samples_leaf': 21, 'max_depth': 3, 'learning_rate': 0.008356216504847113}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:13,449]\u001b[0m Trial 34 finished with value: 29.31215112170453 and parameters: {'n_estimators': 519, 'min_samples_split': 25, 'min_samples_leaf': 24, 'max_depth': 5, 'learning_rate': 0.016348753611393853}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:14,017]\u001b[0m Trial 35 finished with value: 27.95818187667186 and parameters: {'n_estimators': 111, 'min_samples_split': 21, 'min_samples_leaf': 18, 'max_depth': 2, 'learning_rate': 0.008246809309641842}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:15,605]\u001b[0m Trial 36 finished with value: 28.631697715412756 and parameters: {'n_estimators': 205, 'min_samples_split': 20, 'min_samples_leaf': 18, 'max_depth': 4, 'learning_rate': 0.01967130719812891}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:16,676]\u001b[0m Trial 37 finished with value: 28.148229556553474 and parameters: {'n_estimators': 116, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_depth': 5, 'learning_rate': 0.00789738738306337}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:18,799]\u001b[0m Trial 38 finished with value: 27.991736921109034 and parameters: {'n_estimators': 338, 'min_samples_split': 10, 'min_samples_leaf': 19, 'max_depth': 3, 'learning_rate': 0.0018953752110904083}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:20,820]\u001b[0m Trial 39 finished with value: 29.03670592555589 and parameters: {'n_estimators': 321, 'min_samples_split': 10, 'min_samples_leaf': 18, 'max_depth': 3, 'learning_rate': 0.032683681359532826}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:24,109]\u001b[0m Trial 40 finished with value: 28.759060582367752 and parameters: {'n_estimators': 527, 'min_samples_split': 27, 'min_samples_leaf': 16, 'max_depth': 3, 'learning_rate': 0.014967631503906315}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:27,512]\u001b[0m Trial 41 finished with value: 28.16536149330601 and parameters: {'n_estimators': 709, 'min_samples_split': 14, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.006236735481966295}. Best is trial 22 with value: 27.945050870082444.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:28,379]\u001b[0m Trial 42 finished with value: 27.94498626078187 and parameters: {'n_estimators': 174, 'min_samples_split': 11, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.002432649678742187}. Best is trial 42 with value: 27.94498626078187.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:29,082]\u001b[0m Trial 43 finished with value: 28.010100228932046 and parameters: {'n_estimators': 103, 'min_samples_split': 11, 'min_samples_leaf': 19, 'max_depth': 3, 'learning_rate': 0.008655256590882492}. Best is trial 42 with value: 27.94498626078187.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:30,802]\u001b[0m Trial 44 finished with value: 27.943800052636856 and parameters: {'n_estimators': 340, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.0010918677630614296}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:32,376]\u001b[0m Trial 45 finished with value: 28.320659097954536 and parameters: {'n_estimators': 193, 'min_samples_split': 7, 'min_samples_leaf': 12, 'max_depth': 4, 'learning_rate': 0.012802139456159234}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:35,285]\u001b[0m Trial 46 finished with value: 28.61850297416035 and parameters: {'n_estimators': 577, 'min_samples_split': 9, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.02115636012466955}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:36,299]\u001b[0m Trial 47 finished with value: 27.995631145570925 and parameters: {'n_estimators': 194, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_depth': 2, 'learning_rate': 0.007765264851600151}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:39,330]\u001b[0m Trial 48 finished with value: 27.989019916510355 and parameters: {'n_estimators': 464, 'min_samples_split': 15, 'min_samples_leaf': 16, 'max_depth': 3, 'learning_rate': 0.0012492626122687757}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 21:49:40,820]\u001b[0m Trial 49 finished with value: 28.016133456343237 and parameters: {'n_estimators': 294, 'min_samples_split': 13, 'min_samples_leaf': 14, 'max_depth': 2, 'learning_rate': 0.006513276377773545}. Best is trial 44 with value: 27.943800052636856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination for GradientBoostingRegressor with top-7 variables: \n",
      " {'n_estimators': 340, 'min_samples_split': 8, 'min_samples_leaf': 20, 'max_depth': 2, 'learning_rate': 0.0010918677630614296}\n"
     ]
    }
   ],
   "source": [
    "#Model: Gradient Boosting\n",
    "\n",
    "SEED = 42\n",
    "N_TRIALS = 50\n",
    "\n",
    "#Optuna w/ top 7 most important features:----------\n",
    "class Objective:\n",
    "    \n",
    "    def __init__(self, seed):\n",
    "        \n",
    "        self.seed = seed\n",
    "        \n",
    "    def __call__(self, trial):\n",
    "        \n",
    "        params = dict(n_estimators = trial.suggest_int('n_estimators', 100, 2000), \n",
    "                      min_samples_split = trial.suggest_int('min_samples_split', 5, 30),\n",
    "                      min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 30),\n",
    "                      max_depth = trial.suggest_int('max_depth', 2, 10),\n",
    "                      learning_rate = trial.suggest_float('learning_rate', 0.001, .1))\n",
    "        \n",
    "        scores = list()\n",
    "        \n",
    "        skf = KFold(n_splits = 3, shuffle = True, random_state = self.seed)\n",
    "        \n",
    "        for train_idx, valid_idx in skf.split(x_train, y_train):\n",
    "            \n",
    "            x_train_1, x_valid_1 = x_train.iloc[train_idx], x_train.iloc[valid_idx]\n",
    "            y_train_1, y_valid_1 = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "            \n",
    "            gb_md = GradientBoostingRegressor(**params).fit(x_train_1,y_train_1)\n",
    "            \n",
    "            pred_valid = gb_md.predict(x_valid_1)\n",
    "            \n",
    "            scores.append(mean_squared_error(y_valid_1, pred_valid, squared = False))   \n",
    "            \n",
    "        return np.mean(scores)\n",
    "\n",
    "study_2 = optuna.create_study(direction = 'minimize')\n",
    "study_2.optimize(Objective(SEED), n_trials = N_TRIALS)\n",
    "\n",
    "print('Best hyper-parameter combination for GradientBoostingRegressor with top-7 variables: \\n', study_2.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c20a353d-c121-4bf5-83db-ae11ba1bd9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE of the Gradient Boosting model is:  27.83856771994153\n"
     ]
    }
   ],
   "source": [
    "#running model with best parameters\n",
    "gb_md = GradientBoostingRegressor(**study_2.best_trial.params).fit(x_train, y_train)\n",
    "\n",
    "#predicting on test\n",
    "gb_pred = gb_md.predict(x_test)\n",
    "\n",
    "#computing rmse\n",
    "gb_results = mean_squared_error(y_test, gb_pred, squared = False)\n",
    "print('the RMSE of the Gradient Boosting model is: ', gb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80656a-bb31-4526-9298-6bb0548e199e",
   "metadata": {},
   "source": [
    "*(f) (20 points) Using results from Exercise 16 part (e) in Exam 1, use the top 7 variables, build another model (different from the one in parts (d)-(e)) on the train data-frame, and tune this model using the Optuna framework. Notice that you need to tune the model based on the root mean squared error. Then, use the optimal model to make predictions on the test data-frame. Finally, compute the root mean squared error of the model. Make sure to run at least 50 trials the Optuna framework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1bceac3-2d86-463b-ba11-f7bc70367434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-04 22:29:44,770]\u001b[0m A new study created in memory with name: no-name-f4ed9ec1-aa6c-48e7-b65b-6693b95926bc\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:29:50,084]\u001b[0m Trial 0 finished with value: 30.088212718420493 and parameters: {'n_estimators': 1649, 'max_depth': 10, 'min_child_weight': 20, 'learning_rate': 0.004585324232038347, 'gamma': 8.42258359764002, 'colsample_bytree': 0.8758062557586248, 'subsample': 0.698446905426491}. Best is trial 0 with value: 30.088212718420493.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:29:52,954]\u001b[0m Trial 1 finished with value: 32.230415352196694 and parameters: {'n_estimators': 1883, 'max_depth': 6, 'min_child_weight': 12, 'learning_rate': 0.03443410107272345, 'gamma': 6.598857673416909, 'colsample_bytree': 0.27204193963143014, 'subsample': 0.4209835343765423}. Best is trial 0 with value: 30.088212718420493.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:29:56,073]\u001b[0m Trial 2 finished with value: 33.03839226692882 and parameters: {'n_estimators': 1767, 'max_depth': 7, 'min_child_weight': 16, 'learning_rate': 0.041268157039171395, 'gamma': 4.9621546821, 'colsample_bytree': 0.3101804005905954, 'subsample': 0.375221897675706}. Best is trial 0 with value: 30.088212718420493.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:29:59,516]\u001b[0m Trial 3 finished with value: 28.97835230613579 and parameters: {'n_estimators': 1431, 'max_depth': 6, 'min_child_weight': 4, 'learning_rate': 0.0032508162965153293, 'gamma': 4.860658852820451, 'colsample_bytree': 0.8281465501702261, 'subsample': 0.8881319857875807}. Best is trial 3 with value: 28.97835230613579.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:29:59,812]\u001b[0m Trial 4 finished with value: 46.947526196673685 and parameters: {'n_estimators': 137, 'max_depth': 6, 'min_child_weight': 6, 'learning_rate': 0.002159231887801538, 'gamma': 8.111198072535137, 'colsample_bytree': 0.5231817149281809, 'subsample': 0.6532446405505429}. Best is trial 3 with value: 28.97835230613579.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:30:02,482]\u001b[0m Trial 5 finished with value: 28.51944043956584 and parameters: {'n_estimators': 1906, 'max_depth': 4, 'min_child_weight': 9, 'learning_rate': 0.0017142750411346542, 'gamma': 5.738600987399166, 'colsample_bytree': 0.7209616818111391, 'subsample': 0.300403438813477}. Best is trial 5 with value: 28.51944043956584.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:30:04,421]\u001b[0m Trial 6 finished with value: 29.78288674920636 and parameters: {'n_estimators': 1402, 'max_depth': 3, 'min_child_weight': 10, 'learning_rate': 0.0011629238962406003, 'gamma': 5.887857145571119, 'colsample_bytree': 0.7804893203796595, 'subsample': 0.7582437261321595}. Best is trial 5 with value: 28.51944043956584.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:30:07,124]\u001b[0m Trial 7 finished with value: 29.88581889651304 and parameters: {'n_estimators': 1325, 'max_depth': 8, 'min_child_weight': 6, 'learning_rate': 0.0013860567251973515, 'gamma': 1.7544869363552695, 'colsample_bytree': 0.8284850369168593, 'subsample': 0.22601932084209755}. Best is trial 5 with value: 28.51944043956584.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:30:08,571]\u001b[0m Trial 8 finished with value: 28.775820675643576 and parameters: {'n_estimators': 706, 'max_depth': 9, 'min_child_weight': 17, 'learning_rate': 0.0034110240747257385, 'gamma': 7.890944091558259, 'colsample_bytree': 0.35599665251436985, 'subsample': 0.5134024916303113}. Best is trial 5 with value: 28.51944043956584.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 22:30:09,126]\u001b[0m Trial 9 finished with value: 29.178767652561657 and parameters: {'n_estimators': 331, 'max_depth': 9, 'min_child_weight': 16, 'learning_rate': 0.03262409311703036, 'gamma': 4.34892622376534, 'colsample_bytree': 0.2474298852665282, 'subsample': 0.3366560705523604}. Best is trial 5 with value: 28.51944043956584.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:10,089]\u001b[0m Trial 10 finished with value: 28.515791403255076 and parameters: {'n_estimators': 950, 'max_depth': 2, 'min_child_weight': 10, 'learning_rate': 0.012031658271772926, 'gamma': 9.782500834662553, 'colsample_bytree': 0.6594322279996934, 'subsample': 0.200445607633073}. Best is trial 10 with value: 28.515791403255076.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:10,986]\u001b[0m Trial 11 finished with value: 28.416035041594284 and parameters: {'n_estimators': 877, 'max_depth': 2, 'min_child_weight': 10, 'learning_rate': 0.009928039363881263, 'gamma': 9.62093865299276, 'colsample_bytree': 0.6636387975479116, 'subsample': 0.20386508100553313}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:11,906]\u001b[0m Trial 12 finished with value: 28.50414697005266 and parameters: {'n_estimators': 884, 'max_depth': 2, 'min_child_weight': 12, 'learning_rate': 0.01171356844742825, 'gamma': 9.898996180752405, 'colsample_bytree': 0.6575056559124871, 'subsample': 0.20957792852731455}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:12,826]\u001b[0m Trial 13 finished with value: 28.86260968474367 and parameters: {'n_estimators': 631, 'max_depth': 4, 'min_child_weight': 13, 'learning_rate': 0.011400192237168578, 'gamma': 9.936731328307253, 'colsample_bytree': 0.6023491959181428, 'subsample': 0.26651082736486653}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:13,858]\u001b[0m Trial 14 finished with value: 28.80535584859743 and parameters: {'n_estimators': 1036, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.018674082430090253, 'gamma': 9.818140052818261, 'colsample_bytree': 0.5272737163282117, 'subsample': 0.20443986385130442}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:14,923]\u001b[0m Trial 15 finished with value: 32.30246199529328 and parameters: {'n_estimators': 664, 'max_depth': 4, 'min_child_weight': 8, 'learning_rate': 0.0757334776055265, 'gamma': 8.825313294974567, 'colsample_bytree': 0.7136078551944831, 'subsample': 0.4211920002490413}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:16,048]\u001b[0m Trial 16 finished with value: 28.5055704258662 and parameters: {'n_estimators': 893, 'max_depth': 3, 'min_child_weight': 14, 'learning_rate': 0.006355546711258238, 'gamma': 7.061112293347232, 'colsample_bytree': 0.6198957608791252, 'subsample': 0.3077025133497181}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:17,351]\u001b[0m Trial 17 finished with value: 28.45211535120369 and parameters: {'n_estimators': 1185, 'max_depth': 2, 'min_child_weight': 3, 'learning_rate': 0.007542671526314689, 'gamma': 8.98981313451532, 'colsample_bytree': 0.4618549237838854, 'subsample': 0.4753848418075996}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:19,688]\u001b[0m Trial 18 finished with value: 29.368362728969924 and parameters: {'n_estimators': 1262, 'max_depth': 5, 'min_child_weight': 2, 'learning_rate': 0.006719341991626591, 'gamma': 7.438799499510189, 'colsample_bytree': 0.4400047130767522, 'subsample': 0.4947934709098924}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:21,362]\u001b[0m Trial 19 finished with value: 28.68698396122893 and parameters: {'n_estimators': 1204, 'max_depth': 3, 'min_child_weight': 3, 'learning_rate': 0.006937756743434461, 'gamma': 8.789693756888385, 'colsample_bytree': 0.4706721552249007, 'subsample': 0.5798537751855997}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:22,047]\u001b[0m Trial 20 finished with value: 28.90057708412755 and parameters: {'n_estimators': 442, 'max_depth': 5, 'min_child_weight': 6, 'learning_rate': 0.019491691193489605, 'gamma': 8.99013141345864, 'colsample_bytree': 0.20753810720695132, 'subsample': 0.38428221496363574}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:22,961]\u001b[0m Trial 21 finished with value: 28.426852641536104 and parameters: {'n_estimators': 876, 'max_depth': 2, 'min_child_weight': 8, 'learning_rate': 0.009724932823752497, 'gamma': 9.91862883876994, 'colsample_bytree': 0.6008875689701942, 'subsample': 0.2578083828041147}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:24,095]\u001b[0m Trial 22 finished with value: 28.43401911511199 and parameters: {'n_estimators': 1103, 'max_depth': 2, 'min_child_weight': 8, 'learning_rate': 0.008333804466356615, 'gamma': 9.061379680966628, 'colsample_bytree': 0.5657928266024161, 'subsample': 0.28271289236622543}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:25,071]\u001b[0m Trial 23 finished with value: 29.044558286244268 and parameters: {'n_estimators': 764, 'max_depth': 3, 'min_child_weight': 7, 'learning_rate': 0.016467601729319117, 'gamma': 7.7800782186535775, 'colsample_bytree': 0.5816508203358159, 'subsample': 0.27765521811736577}. Best is trial 11 with value: 28.416035041594284.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:26,213]\u001b[0m Trial 24 finished with value: 28.22922371148832 and parameters: {'n_estimators': 1098, 'max_depth': 2, 'min_child_weight': 8, 'learning_rate': 0.004554184361452478, 'gamma': 9.105554504848676, 'colsample_bytree': 0.5708128873560737, 'subsample': 0.275780171820087}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:26,954]\u001b[0m Trial 25 finished with value: 28.53638480638087 and parameters: {'n_estimators': 546, 'max_depth': 3, 'min_child_weight': 10, 'learning_rate': 0.004483061365834207, 'gamma': 8.335630787241028, 'colsample_bytree': 0.6545482388746441, 'subsample': 0.3495263723062565}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:29,147]\u001b[0m Trial 26 finished with value: 28.984627376592087 and parameters: {'n_estimators': 1515, 'max_depth': 4, 'min_child_weight': 5, 'learning_rate': 0.005034790186746631, 'gamma': 7.157075977532353, 'colsample_bytree': 0.7316555698553505, 'subsample': 0.26938936111369727}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:30,483]\u001b[0m Trial 27 finished with value: 28.851470669674445 and parameters: {'n_estimators': 823, 'max_depth': 5, 'min_child_weight': 8, 'learning_rate': 0.00277550006173605, 'gamma': 9.621942554341572, 'colsample_bytree': 0.5466623401929729, 'subsample': 0.3357820153353315}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:31,532]\u001b[0m Trial 28 finished with value: 28.497378551211927 and parameters: {'n_estimators': 1028, 'max_depth': 2, 'min_child_weight': 11, 'learning_rate': 0.010225314287120934, 'gamma': 9.337777098898492, 'colsample_bytree': 0.6303687737527418, 'subsample': 0.24214296720073172}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:33,942]\u001b[0m Trial 29 finished with value: 28.885240968167793 and parameters: {'n_estimators': 1538, 'max_depth': 10, 'min_child_weight': 20, 'learning_rate': 0.005094252714926863, 'gamma': 8.448483952757854, 'colsample_bytree': 0.586438472590587, 'subsample': 0.24695277755238784}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:34,530]\u001b[0m Trial 30 finished with value: 29.321839751447595 and parameters: {'n_estimators': 437, 'max_depth': 3, 'min_child_weight': 9, 'learning_rate': 0.004174303889154216, 'gamma': 8.232668387947754, 'colsample_bytree': 0.680033239360275, 'subsample': 0.3130163798531712}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:35,619]\u001b[0m Trial 31 finished with value: 28.390004485087392 and parameters: {'n_estimators': 1040, 'max_depth': 2, 'min_child_weight': 8, 'learning_rate': 0.008288071810136846, 'gamma': 8.985053134818527, 'colsample_bytree': 0.5636423997340163, 'subsample': 0.27861767139874144}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:36,762]\u001b[0m Trial 32 finished with value: 28.482171194601808 and parameters: {'n_estimators': 1122, 'max_depth': 2, 'min_child_weight': 7, 'learning_rate': 0.00870478168100947, 'gamma': 9.307018821750182, 'colsample_bytree': 0.6114548890014955, 'subsample': 0.2504451532666375}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:38,026]\u001b[0m Trial 33 finished with value: 28.412225753342337 and parameters: {'n_estimators': 969, 'max_depth': 3, 'min_child_weight': 11, 'learning_rate': 0.005438570377328379, 'gamma': 8.527173123326431, 'colsample_bytree': 0.5331899563348913, 'subsample': 0.41216003809266005}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:39,284]\u001b[0m Trial 34 finished with value: 28.422874001834202 and parameters: {'n_estimators': 977, 'max_depth': 3, 'min_child_weight': 11, 'learning_rate': 0.005207704709129639, 'gamma': 8.453341249912581, 'colsample_bytree': 0.5174036439355549, 'subsample': 0.39021515982691807}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:41,691]\u001b[0m Trial 35 finished with value: 28.467840997762707 and parameters: {'n_estimators': 1632, 'max_depth': 4, 'min_child_weight': 12, 'learning_rate': 0.0025730562165429886, 'gamma': 7.481637233955727, 'colsample_bytree': 0.4956788667180283, 'subsample': 0.42437561022571224}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:43,140]\u001b[0m Trial 36 finished with value: 28.716686162966585 and parameters: {'n_estimators': 773, 'max_depth': 7, 'min_child_weight': 9, 'learning_rate': 0.0032490582450825523, 'gamma': 9.247109748684561, 'colsample_bytree': 0.4165623333900945, 'subsample': 0.35729900867336095}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:44,721]\u001b[0m Trial 37 finished with value: 28.389406816893587 and parameters: {'n_estimators': 1323, 'max_depth': 3, 'min_child_weight': 14, 'learning_rate': 0.002046857877589564, 'gamma': 6.9352308794588025, 'colsample_bytree': 0.5594766647335356, 'subsample': 0.3124946090957927}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:47,387]\u001b[0m Trial 38 finished with value: 28.474000630668574 and parameters: {'n_estimators': 1769, 'max_depth': 5, 'min_child_weight': 16, 'learning_rate': 0.00202391521509982, 'gamma': 6.5735767353300325, 'colsample_bytree': 0.5459081966054993, 'subsample': 0.30907701595363635}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:49,315]\u001b[0m Trial 39 finished with value: 28.805485686577384 and parameters: {'n_estimators': 1331, 'max_depth': 4, 'min_child_weight': 15, 'learning_rate': 0.0016436119943749204, 'gamma': 7.982793051681604, 'colsample_bytree': 0.5011924277910655, 'subsample': 0.3925797050772136}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:51,147]\u001b[0m Trial 40 finished with value: 30.07081365251935 and parameters: {'n_estimators': 1412, 'max_depth': 3, 'min_child_weight': 18, 'learning_rate': 0.001106661888894731, 'gamma': 8.630106757163597, 'colsample_bytree': 0.57756655854952, 'subsample': 0.45234896509147987}. Best is trial 24 with value: 28.22922371148832.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:52,299]\u001b[0m Trial 41 finished with value: 28.185977979158025 and parameters: {'n_estimators': 1107, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.0034067682634491576, 'gamma': 7.848446222453216, 'colsample_bytree': 0.5407424103244909, 'subsample': 0.3132431154856266}. Best is trial 41 with value: 28.185977979158025.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:53,873]\u001b[0m Trial 42 finished with value: 28.343443979539476 and parameters: {'n_estimators': 1276, 'max_depth': 3, 'min_child_weight': 14, 'learning_rate': 0.003509528980609385, 'gamma': 7.8102483868428685, 'colsample_bytree': 0.5406339641864808, 'subsample': 0.3395712452297703}. Best is trial 41 with value: 28.185977979158025.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:55,223]\u001b[0m Trial 43 finished with value: 28.198391422244285 and parameters: {'n_estimators': 1293, 'max_depth': 2, 'min_child_weight': 14, 'learning_rate': 0.0033338200214620105, 'gamma': 7.812738249560988, 'colsample_bytree': 0.5578740178875474, 'subsample': 0.33950030064771247}. Best is trial 41 with value: 28.185977979158025.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:57,659]\u001b[0m Trial 44 finished with value: 28.793613946513734 and parameters: {'n_estimators': 1313, 'max_depth': 7, 'min_child_weight': 14, 'learning_rate': 0.0035611856360562807, 'gamma': 6.299758734488841, 'colsample_bytree': 0.4873160065860228, 'subsample': 0.3370312527743415}. Best is trial 41 with value: 28.185977979158025.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:30:59,553]\u001b[0m Trial 45 finished with value: 28.27523688658494 and parameters: {'n_estimators': 1493, 'max_depth': 3, 'min_child_weight': 14, 'learning_rate': 0.0021514790372030037, 'gamma': 7.897943831504245, 'colsample_bytree': 0.4083086951164257, 'subsample': 0.3207697463590826}. Best is trial 41 with value: 28.185977979158025.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:31:01,117]\u001b[0m Trial 46 finished with value: 28.166317155340476 and parameters: {'n_estimators': 1517, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.0027160167543365107, 'gamma': 7.714742420788344, 'colsample_bytree': 0.39086992070842974, 'subsample': 0.3693192002420051}. Best is trial 46 with value: 28.166317155340476.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:31:02,924]\u001b[0m Trial 47 finished with value: 28.200694414620003 and parameters: {'n_estimators': 1792, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.002544439813834562, 'gamma': 7.3651624662747075, 'colsample_bytree': 0.3907857441372176, 'subsample': 0.36442062069068343}. Best is trial 46 with value: 28.166317155340476.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:31:04,899]\u001b[0m Trial 48 finished with value: 28.23078871190071 and parameters: {'n_estimators': 1947, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.0026917850686031287, 'gamma': 5.817047813639387, 'colsample_bytree': 0.3495104187909342, 'subsample': 0.36228019938625217}. Best is trial 46 with value: 28.166317155340476.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/optuna/samplers/_tpe/_erf.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  s = one / (x * x)\n",
      "\u001b[32m[I 2023-04-04 22:31:06,760]\u001b[0m Trial 49 finished with value: 28.249016271621816 and parameters: {'n_estimators': 1797, 'max_depth': 2, 'min_child_weight': 17, 'learning_rate': 0.0015735799800418264, 'gamma': 7.549855020546393, 'colsample_bytree': 0.3085795412490621, 'subsample': 0.37028540676007055}. Best is trial 46 with value: 28.166317155340476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination for XGBRegressor with top-7 variables: \n",
      " {'n_estimators': 1517, 'max_depth': 2, 'min_child_weight': 13, 'learning_rate': 0.0027160167543365107, 'gamma': 7.714742420788344, 'colsample_bytree': 0.39086992070842974, 'subsample': 0.3693192002420051}\n"
     ]
    }
   ],
   "source": [
    "#Model: XGBoost\n",
    "\n",
    "SEED = 42\n",
    "N_TRIALS = 50\n",
    "\n",
    "#Optuna w/ top 7 most important features:----------\n",
    "class Objective:\n",
    "    \n",
    "    def __init__(self, seed):\n",
    "        \n",
    "        self.seed = seed\n",
    "        \n",
    "    def __call__(self, trial):\n",
    "        \n",
    "        params = dict(n_estimators = trial.suggest_int('n_estimators', 100, 2000),\n",
    "                      max_depth = trial.suggest_int('max_depth', 2, 10),\n",
    "                      min_child_weight = trial.suggest_int('min_child_weight', 2, 20),\n",
    "                      learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log = True),\n",
    "                      gamma = trial.suggest_float('gamma', 0.0, 10.0),\n",
    "                      colsample_bytree = trial.suggest_float('colsample_bytree', 0.2, 0.9),\n",
    "                      subsample = trial.suggest_float('subsample', 0.2, 0.9))\n",
    "        \n",
    "        scores = list()\n",
    "        \n",
    "        skf = KFold(n_splits = 3, shuffle = True, random_state = self.seed)\n",
    "        \n",
    "        for train_idx, valid_idx in skf.split(x_train, y_train):\n",
    "            \n",
    "            x_train_1, x_valid_1 = x_train.iloc[train_idx], x_train.iloc[valid_idx]\n",
    "            y_train_1, y_valid_1 = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "            \n",
    "            xgb_md = XGBRegressor(**params).fit(x_train_1,y_train_1)\n",
    "            \n",
    "            pred_valid = xgb_md.predict(x_valid_1)\n",
    "            \n",
    "            scores.append(mean_squared_error(y_valid_1, pred_valid, squared = False))   \n",
    "            \n",
    "        return np.mean(scores)\n",
    "\n",
    "study_3 = optuna.create_study(direction = 'minimize')\n",
    "study_3.optimize(Objective(SEED), n_trials = N_TRIALS)\n",
    "\n",
    "print('Best hyper-parameter combination for XGBRegressor with top-7 variables: \\n', study_3.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bebf9b33-3eb3-416a-8869-ca0d55426c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE of the Gradient Boosting model is:  27.837240813963206\n"
     ]
    }
   ],
   "source": [
    "#running model with best parameters\n",
    "xgb_md = XGBRegressor(**study_3.best_trial.params).fit(x_train, y_train)\n",
    "\n",
    "#predicting on test\n",
    "xgb_pred = xgb_md.predict(x_test)\n",
    "\n",
    "#computing rmse\n",
    "xgb_results = mean_squared_error(y_test, xgb_pred, squared = False)\n",
    "print('the RMSE of the Gradient Boosting model is: ', xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e9b32-01a0-4ed1-afff-87f4e7398b80",
   "metadata": {},
   "source": [
    "*(g) (20 points) Using the predictions from parts (d), (e), and (f), ensemble them by taking the average of those predictions. Finally, compute the root mean squared error of this ensemble.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28d17ca2-88ab-4b48-a4f9-3c3515bb8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the ensemble:  27.78771261215174\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = (rf_pred + gb_pred + xgb_pred)/3\n",
    "ensemble_results = mean_squared_error(y_test, ensemble_pred, squared = False)\n",
    "print('RMSE of the ensemble: ', ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5967e-1658-47b9-bf19-ef7c2b5ada21",
   "metadata": {},
   "source": [
    "*(h) (5 points), Using the results from parts (d) to (g), what model/approach would use to predict Spending Score. Be specific.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e8b354a-e8b5-4a2c-bd54-dc3831016a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Random Forest:  27.734948112775353\n",
      "RMSE of Gradient Boosting:  27.83856771994153\n",
      "RMSE of XGBoost:  27.837240813963206\n",
      "RMSE of the ensemble:  27.78771261215174\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of Random Forest: ', rf_results)\n",
    "print('RMSE of Gradient Boosting: ', gb_results)\n",
    "print('RMSE of XGBoost: ', xgb_results)\n",
    "print('RMSE of the ensemble: ', ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc5d79-c202-44f1-b711-d034470f5188",
   "metadata": {},
   "source": [
    "Based on the results above, the random forest model is better for predicting Spending Score because it has the lowest RMSE (27.73)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
